{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Flow matching\n",
    "\n",
    "Linear Gaussian Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as l\n",
    "from torch import optim, nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import ot\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Flow(l.LightningModule):\n",
    "    def __init__(self, net=None, dim: int =2, h: int = 64):\n",
    "        super().__init__()\n",
    "        if net is None:\n",
    "            net = nn.Sequential(\n",
    "                nn.Linear(dim+1, h), nn.SiLU(), # input dim, +1 for time\n",
    "                nn.Linear(h, h), nn.SiLU(),\n",
    "                nn.Linear(h, h), nn.SiLU(),\n",
    "                nn.Linear(h, dim)\n",
    "            )\n",
    "        self.net = net\n",
    "        self.criterion = F.mse_loss\n",
    "\n",
    "        # net will be trained to predict the flow vector field.\n",
    "\n",
    "    def compute_noisy_sample(self, x, t, noise):\n",
    "        # t=0 : noise distribution t=1: data distribution\n",
    "        xt = (1-t)*noise + t*x\n",
    "        return xt\n",
    "\n",
    "    def training_step(self, x):\n",
    "        # Ground Truth Image batches will be fed. compute flow matching loss here.\n",
    "        \n",
    "        ts = torch.rand(x.size(0), 1).to(x.device)\n",
    "        noise = torch.randn_like(x)\n",
    "        xt = self.compute_noisy_sample(x, ts, noise)\n",
    "        flow_pred = self.net(torch.cat([xt, ts], dim=-1))\n",
    "        flow = x - noise\n",
    "        loss = self.criterion(flow_pred, flow)\n",
    "        \n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, x):\n",
    "        \n",
    "        # Generate samples\n",
    "        generated_samples = self.generate(sample_steps=100, num_samples=x.size(0))\n",
    "\n",
    "        # Compute cost matrix (pairwise distances)\n",
    "        cost_matrix = ot.dist(x.cpu().numpy(), generated_samples.cpu().numpy(), metric='euclidean')\n",
    "\n",
    "        # Uniform weights for both distributions\n",
    "        weights = np.ones(x.size(0)) / x.size(0)\n",
    "\n",
    "        # Compute Earth Mover's Distance\n",
    "        emd = ot.emd2(weights, weights, cost_matrix)\n",
    "\n",
    "        # Log EMD as a validation metric\n",
    "        self.log('val_emd', emd)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-2)\n",
    "        return optimizer\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, sample_steps: int = 100, num_samples: int = 1):\n",
    "        xt = torch.randn(num_samples, 2).to(self.device)\n",
    "        ts = torch.linspace(0, 1, sample_steps).to(self.device)\n",
    "        dt = ts[1] - ts[0]\n",
    "        for t in ts[:-1]:\n",
    "            flow = self.net(torch.cat([xt, t*torch.ones_like(xt[:, 0:1])], dim=-1))\n",
    "            x_mid = xt + flow*dt/2\n",
    "            mid_t = t + dt/2\n",
    "            xt = xt + dt * self.net(torch.cat([x_mid, mid_t*torch.ones_like(x_mid[:, 0:1])], dim=-1))\n",
    "        return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d data generation. with make moon\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.1)\n",
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y).float()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class PlotSamplesCallback(Callback):\n",
    "    def __init__(self, interval=5, save_dir=\"generated_samples\"):\n",
    "        \"\"\"\n",
    "        Callback to plot and save generated samples during training.\n",
    "        \n",
    "        Args:\n",
    "            interval (int): Frequency of epochs at which to generate plots.\n",
    "            save_dir (str): Directory where plots and sample data will be saved.\n",
    "        \"\"\"\n",
    "        self.interval = interval\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(save_dir, exist_ok=True)  # Ensure the save directory exists\n",
    "        \n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if trainer.current_epoch % self.interval == 0:\n",
    "            # Generate samples\n",
    "            samples = pl_module.generate(num_samples=500)  # Ensure `generate` is implemented in your model\n",
    "            samples = samples.detach().cpu().numpy()\n",
    "            # Plot samples\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(samples[:, 0], samples[:, 1], c='r', s=10)\n",
    "            plt.title(f\"Generated Samples - Epoch {trainer.current_epoch}\")\n",
    "            plt.xlabel(\"X-axis\")\n",
    "            plt.ylabel(\"Y-axis\")\n",
    "            \n",
    "            # Save plot\n",
    "            plot_path = os.path.join(self.save_dir, f\"epoch_{trainer.current_epoch}.png\")\n",
    "            plt.savefig(plot_path)\n",
    "            plt.close()  # Close the plot to free memory\n",
    "            \n",
    "            # Save sample data\n",
    "            samples_path = os.path.join(self.save_dir, f\"samples_epoch_{trainer.current_epoch}.npy\")\n",
    "            np.save(samples_path, samples)\n",
    "\n",
    "            # Log the plot to TensorBoard\n",
    "            trainer.logger.experiment.add_image(\n",
    "                \"generated samples\", plt.imread(plot_path), dataformats='HWC', global_step=trainer.global_step\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "class MoonDataLoader(l.LightningDataModule):\n",
    "    def __init__(self, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        X_train, _ = make_moons(n_samples=5000, noise=0.1)\n",
    "        X_test, _ = make_moons(n_samples=1000, noise=0.1)\n",
    "        self.X_train = torch.tensor(X_train).float()\n",
    "        \n",
    "        self.X_test = torch.tensor(X_test).float()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.X_train, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        return DataLoader(self.X_test, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Define TensorBoard logger\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"simple_flow\")\n",
    "# Lightning Trainer with callback\n",
    "model = Flow()\n",
    "plot_callback = PlotSamplesCallback(interval=5)\n",
    "trainer = l.Trainer(max_epochs=10000, callbacks=[plot_callback], logger=logger, check_val_every_n_epoch=5)\n",
    "trainer.fit(model, MoonDataLoader(batch_size=516))\n",
    "\n",
    "# Generate samples\n",
    "samples = model.generate(num_samples=1000, sample_steps = 100)\n",
    "plt.scatter(samples[:, 0], samples[:, 1], c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = make_moons(n_samples=5000, noise=0.1)\n",
    "X_test, y_test = make_moons(n_samples=1000, noise=0.1)\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(X_train, batch_size=64, shuffle=True)\n",
    "\n",
    "# get one batch from dataloader\n",
    "x = next(iter(dataloader))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
